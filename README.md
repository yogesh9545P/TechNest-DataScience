# ğŸ§ª Titanic Data Pipeline â€” ETL Project

This project demonstrates a complete **ETL (Extract, Transform, Load)** pipeline on the famous Titanic dataset using Python and pandas in Jupyter Notebook.

---

## ğŸ“Œ Project Overview

- **Extract:** Load the Titanic dataset from a CSV file
- **Transform:** 
  - Handle missing values (Age, Embarked)
  - Drop unnecessary columns
  - Convert categorical data (Sex, Embarked)
- **Load:** Export the cleaned dataset to a new CSV file

Includes a **visual ETL process diagram** for better understanding.

---

## ğŸ“Š Output Files

- `cleaned_titanic.csv`: Cleaned dataset ready for analysis
- `etl_titanic_process.png`: Visual explanation of ETL steps
- `Titanic_Data_Pipeline_with_ETL_Image.ipynb`: Full working notebook

---

## ğŸ“· ETL Diagram

![ETL Diagram](![etl_titanic_process png](https://github.com/user-attachments/assets/0bc9f3bb-db96-4ad7-bae2-0f6c2680c876)
)

---

## ğŸ› ï¸ Tools Used

- Python (pandas, numpy)
- Jupyter Notebook
- GitHub

---


---

## ğŸ“¦ Dataset

The dataset used in this project is the **Titanic Survival Dataset**, originally sourced from [Kaggle's Titanic Challenge](https://www.kaggle.com/competitions/titanic).

### ğŸ“ Files Used

| Filename                                     | Description                                          |
| -------------------------------------------- | ---------------------------------------------------- |
| `Titanic-Csv.csv`                            | Raw Titanic passenger data                           |
| `cleaned_titanic.csv`                        | Cleaned dataset after ETL process                    |
| `etl_titanic_process.png`                    | Visual representation of the ETL steps               |
| `Titanic_Data_Pipeline_with_ETL_Image.ipynb` | Jupyter Notebook containing full ETL code and visual |

---

## âš™ï¸ Setup Instructions

To run this project on your local machine:

### ğŸ”¹ 1. Clone the Repository

```bash
git clone https://github.com/yogesh9545P/Titanic-Data-Pipeline.git
cd Titanic-Data-Pipeline
```

### ğŸ”¹ 2. Install Required Libraries

Make sure you have Python installed (version 3.7+ recommended). Then install the dependencies:

```bash
pip install pandas numpy
```

### ğŸ”¹ 3. Open the Jupyter Notebook

```bash
jupyter notebook Titanic_Data_Pipeline_with_ETL_Image.ipynb
```

Make sure the following files are present in the same folder as the notebook:

* `Titanic-Csv.csv`
* `![etl_titanic_process png](https://github.com/user-attachments/assets/b6426a09-de10-4140-acf9-480389418451)
`

---

## âœ… Output

Once the notebook runs successfully, a new file `cleaned_titanic.csv` will be created with the processed and cleaned data ready for further analysis or modeling.


Author
Yogesh Pacharane
Data Science Intern @ TechNest
Linkdin | Github


